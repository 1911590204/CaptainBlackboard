# 　　　　　　　                 CNN可视化之类激活热力图CAM
## 引言

卷积神经网络因为其在很多任务上效果很好但是其学到的内容和规则很难用人类理解的方式来呈现（相对于传统机器学习算法，例如决策树或者逻辑回归等），所以被很多人认为是“黑盒”。如果我们可以可视化

1. 网络模型里面的**中间层的激活**结果；
2. 或者网络学到的**过滤器**是提取什么类型特征的；
3. 或者是图像中哪些位置的像素对输出有着强烈的影响，换句话说，**输出对哪些位置的像素值比较敏感**。

那么无疑对我们理解模型，或者分析模型为什么犯错有着很实际的用处。

所幸的是，2013年以来，随着深度学习的发展，也有一些很好的论文研究深度学习中模型可视化这一领域并取得了一些成果。例如，2014年ECCV上Zeiler的《Visualizing and Understanding Convolutional Networks》研究了第一个问题，此文也是可视化这一领域的开山之作；2012年NIPS上Alex Krizhevsky发表的AlexNet应该是最早可视化过滤器的文章；而针对第三个问题，2016年的**CAM** 《Learning deep features for discriminative localization》，2017年的**Grad-CAM** 《Grad-CAM:Visual Explanations from Deep Networks via Gradient-based Localization》和紧接着2018年的**Grad-CAM++** 《Grad-CAM++: Generalized Gradient-based Visual Explanations for Deep Convolutional Networks》这一系列的文章都对**类激活图**(**C**lass **A**ctivation **M**ap)这种可视化技术做了比较充分的研究。

本文结合论文和有关资料，详细描述一些Grad-CAM这种可视化的方法。

**欢迎探讨，本文持续维护。**

## 实验平台

N/A

## Grad CAM的基本思路推导

。

## Grad CAM的代码实现过程

。

## 总结

。

## 参考资料

+ [Visualizing and Understanding Convolutional Networks](https://arxiv.org/abs/1311.2901)
+ [Understanding Neural Networks Through Deep Visualization](https://arxiv.org/abs/1506.06579)
+ [Learning deep features for discriminative localization](https://arxiv.org/pdf/1512.04150.pdf)
+ [Grad-CAM:Visual Explanations from Deep Networks via Gradient-based Localization](https://arxiv.org/abs/1610.02391)
+ [Grad-CAM++: Generalized Gradient-based Visual Explanations for Deep Convolutional Networks](https://arxiv.org/abs/1710.11063v1)
+ [《Python深度学习》](https://book.douban.com/subject/30293801/)
