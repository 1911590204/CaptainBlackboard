# 　　　　　　separable convolutions in image processing
## 引言
在计算机图像处理中，有一种经常进行的操作，就是图像滤波，也叫图像卷积（深度学习中的卷积概念也是衍生于它，只不过深度学习中的卷积核是三维的，图像处理中的卷积核是二维的），比如用Canny卷积提取图像中的边缘信息，用Gaussian卷积构造金字塔等等。在深度学习中，深度可分离卷积（Depthwise Separable Convolution）取代传统卷积，可以起到加速（减少计算量）和减小模型大小（参数数量）的作用；类似地，在图像处理中，往往也可以用两个独立的小的卷积串联，取代一个大的卷积，也可以起到减少计算量和减小参数数量的作用。

**请注意，本文所用的术语“卷积convolution”并不是很恰当，恰当的称呼应该叫“滤波filter”或者“空间相关”，卷积的话卷积核要旋转180度。**但太多情况下并不区分这两者，这里将错就错称之为“卷积”，但这并不影响我们的结论。

**欢迎探讨，本文持续维护。**

## 实验平台：

+ 操作系统：Ubuntu 16.04 LTS，Ubuntu 18.04 LTS
+ 编译器：g++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609

  　　　　gcc (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609

### 1，二维Gaussian卷积核的可分离性分析

+ 推导过程：

![](/home/dup/my_github/CaptainBlackboard/D#0005-separable_convolutions_in_image_processing/images/1565291630.jpg)

可以从上图推导过程中看出，一个m行乘以n列的高斯卷积可以分解成一个1行乘以n列的行卷积，之后串联一个m行乘以1列的列卷积的形式，输出保持不变。行卷积的卷积核参数（均值和方差）等于原始m行n列卷积核在列方向（Y方向）的均值和方差，列卷积的卷积核参数等于原始m行n列卷积核在行方向（X方向）上的均值和方差。

+ 计算量分析：

原始卷积的mxn的卷积和，卷积一个图像，乘加次数等于图像的像素个数WxH，乘以以单个像素为中心店做卷积时卷积的乘加次数mxn，总次数等于MxHxmxn。

在把原始卷积拆分为行卷积和列卷积后，行卷积的乘加次数等于输入图像的像素点个数WxH，乘以单个行卷积的乘加次数n，列卷积的乘加次数等于上一步行卷积输出图像的像素点个数WxH，乘以单个列卷积的乘加次数m，所以，总的次数是WxHxn+WxHxm。

由此可见，将卷积分离后的计算量比原始计算量等于(m+n)/(mxn)，常见的宽高相等，假设为k，则计算量的比可以简化为2/k。**计算复杂度从原来的O(k^2)将为了O(k)。**是一个很大的提速。

+ 参数数量分析：

原始卷积的参数数量为mxn个，卷积拆分后的参数数量为n+m。考虑到高斯核的对称性，略有冗余。

### 2，二维Gaussian卷积核的可分离代码实测

### 3，理论推广，什么样的核才可分离

## 总结

// TODO

## 参考资料
+ [《数字图像处理》](https://book.douban.com/subject/6434627/)
+ [高斯滤波器详解](https://www.cnblogs.com/wangguchangqing/p/6407717.html)
