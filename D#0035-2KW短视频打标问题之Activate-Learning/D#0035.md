#                                                海量短视频打标问题之Active-Learning

## 引言

在网络中，每时每刻都会产生很多**无标签**数据信息，比如最近很火的一些短视频APP，每天都有很多用户发布自己生产的短视频(UGC)内容，这些内容一般是部分打了标签或者标签中有很多噪音的，为了进行做推荐或者做分类、识别的训练，需要给这些短视频**自动生成高质量的标签**；而另外，随着人工智能的发展，许多以前积累的数据，需要自动做标注，比如很多医疗领域的核磁共振片子。这只是CV领域(许多数据集已经打标或者很容易打标)，在NLP和推荐领域，这样的问题更加重要和常见。

这些给**海量视频数据打标签**的问题是很常见也很重要的问题，而且这些问题牵扯到机器学习中的“主动学习”(Active Learning)，“多模态机器学习”(MultiModal Machine Learning)，“多标签(Multi-label)分类”，“增量学习”(Incremental Learning)，“在线学习”(Online Learning)，“少样本学习”(Few Shot/Zero Shot Learning)等等领域。

为此，船长打算以海量短视频打标这个具体的问题写几篇(具体写几篇，要看我有多忙lan)文章专门捋一捋这方面的常用算法，这个系列的文章将是第一篇，专注于主动学习领域。

**欢迎探讨，本文持续维护。**

## 实验平台

N/A

## 主动学习基本思路

假设现在有两千万短视频池，需要给他们打上一万个标签。如果手工一个个检查一个个打标签，成本太高，肯定是不现实的。但是我们可以少量打一些标签，比如为1000个视频打标签，这个成本还是可以接收的。然后用这1000个视频和**手动打的标签**去训练一个自动打标签的模型alpha。用模型alpha去给视频池**剩余的样本去预测标签**，根据预测出的标签的信息，根据**一定规则**挑选出某些更有意义的样本，比如2000个，把这些挑选出来的2000个样本**再找人工打标签**（因为经过挑选的，所以数量可以控制少一点）。把这些打标签的数据和训练模型alpha的数据合在一起，形成一个3000个样本的**更大的带标签数据集**训练一个**更好的模型beta**，再用模型beta重复由模型alpha得到模型beta的过程，可以继续生成更更好的模型gamma，把这个过程可以迭代下去，就可以在有限的标注成本下，得到不错的自动打标模型了。

### 主动学习为什么有用？

我们知道，一般而言，样本量越多，训练的模型越好。但是不是所有的样本对最终模型性能的贡献都是一样的（比如我们要描述一个正方体，并不需要穷举列出正方体内所有的点，只需要列举这个正方体的某些定点上的点就行了），如果能找出一些**关键样本**，这些样本对模型训练更加重要，那么自然我们可以只标准哪些关键样本来训练模型啦。

那么，很显然，关键样本的**挑选规则是主动学习成功的关键**，这也是主动学习领域研究比较多的一个问题，后文会有简单介绍两种比较经典的样本挑选规则。

## 主动学习实施

### 算法流程

在前面一节，已经大概介绍了主动学习的一般思路和过程，这里写一下流程吧：

1. 将两千万短视频初始化未标注样本池P；
2. 在样本池中随机选出1000个样本，对齐人工做标注，形成训练集合T；
3. 用训练集合T训练模型M；
4. 用上一步训练出来的模型M预测样本池P中不属于T的样本，得到预测信息Pred；
5. 根据Pred用**挑选规则挑选**出一些样本，给**人工**进行标注，并把新标注的样本和原来训练集合T合并成新的训练集合T；
6. 如果模型M满足性能要求，则终止，否则转到步骤3；

### 挑选规则

主动学习中样本挑选规则是很重要的，主流有如下集中方法：

1. 基于不确定度缩减的方法。比如分类问题中，一般会出现一个概率向量，这个概率向量的信息熵可以认为是模型对分类的不确定度；挑选信息熵最大的那些样本送去给人工进行标注。从几何角度看，这种方法优先选择靠近分类边界的样例。
2. 基于最大两个类别概率差距最小的方法。和上面差不多，只不过选择的标注不是概率向量的信息熵，而是选择那些top1和top2分量差距最小的概率向量所对应的未标注样本送去给人工标注。很好理解，如果模型预测出某个样本有很高的概率属于1类，也有很高的概率属于2类，那么就说明模型对这个样本不是很确定，就需要人工标注给他更多的信息去学习。
3. 预先聚类的方法：预先运行聚类算法预处理，选择样例时优先选择最靠近分类边界的样例和最能代表聚类的样例（即聚类中心）。

## 主动学习和难例挖掘的比较

在CV中常见的提升性能的方法有难例挖掘（在线，离线），也是挑选一些少量关键样本来提升性能，这里做个简单的比较。

### 相同点

主动学习和难例挖掘(Hard Example Mining)很像，都是用训练了的模型去做预测，找出少量可能对模型性能改进有帮助的关键样本，然后用关键样本去帮助模型改进。

### 不同点

但是不同的地方也很明显，主动学习需要人工参与标注，样本挑选规则挑选出来的样本，要送到人那里去做手动标注；而难例挖掘是在所有样本都有标签的前提下，找出那些特别难的样本。

## 总结

本文以为海量短视频打标签为例子，简单介绍了一下主动学习这种实用的学习方法。但是单单靠这一种方法来做海量短视频打标还是**远远不够**的，后续我会再介绍这个问题上用得上的其他技术点。

## 参考资料

+ [Active Learning Tutorial](https://towardsdatascience.com/active-learning-tutorial-57c3398e34d)
+ [Active Learning wiki](https://en.wikipedia.org/wiki/Active_learning_(machine_learning))
+ [爱奇艺短视频分类技术解析](https://mp.weixin.qq.com/s/t801Q3OO_DBrgI60fKSJxQ)
+ [PRCV2018 美图短视频实时分类挑战赛第一名解决方案介绍](https://www.leiphone.com/news/201811/yhkoD7Ty8WRaCBqe.html)
